# -*- coding: utf-8 -*-
"""paraphrasing_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NZ8ye5x3xsVkL4yyyvtzNNjv3hwZmhqp
"""

!pip install torch
!pip install sentence-splitter
!pip install transformers
!pip install SentencePiece

from fastapi import FastAPI, Request
from sentence_transformers import SentenceTransformer, util
from starlette.responses import FileResponse 
from fastapi.staticfiles import StaticFiles
app = FastAPI()
app.mount("/public", StaticFiles(directory="public"), name="public")
import torch
  from typing import List
  from transformers import PegasusForConditionalGeneration, PegasusTokenizer 
  model_name = 'tuner007/pegasus_paraphrase' 
  torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'
  tokenizer = PegasusTokenizer.from_pretrained(model_name)
  model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)

def get_response(input_text,num_return_sequences):
  batch = tokenizer.prepare_seq2seq_batch([input_text],truncation=True,padding='longest',max_length=60, return_tensors="pt").to(torch_device)
  translated = model.generate(**batch,max_length=60,num_beams=10, num_return_sequences=num_return_sequences, temperature=1.5)
  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)
  return tgt_text

#test the model
context = "Which course should I take to get started in data science?"
num_return_sequences = 10
num_beams = 10
get_response(context,num_beams)

from sentence_splitter import SentenceSplitter, split_text_into_sentences
splitter = SentenceSplitter(language='en')

context = "I will be showing you how to build a web application in Python using the SweetViz and its dependent library. Data science combines multiple fields, including statistics, scientific methods, artificial intelligence (AI), and data analysis, to extract value from data. Those who practice data science are called data scientists, and they combine a range of skills to analyze data collected from the web, smartphones, customers, sensors, and other sources to derive actionable insights."
sentence_list = splitter.split(context)
num_return_sequences = 5

get_response(context, num_return_sequences)
paraphrase = [] 
for i in sentence_list:
	a = get_response(i,1)
	paraphrase.append(a)

paraphrase

paraphrase2 = [''.join(x) for x in paraphrase]

paraphrase2

paraphrase3 = [''.join(x for x in paraphrase2) ]

paraphrased_text =str(paraphrase3).strip('[ ]').strip("'")

paraphrased_text
#Calls the model and returns the paraphrased output and some simple metrics. 
@app.post('/paraphrase/')
async def main(item: Request):
    userInput = await item.json()
    input_string = get_input_string(
        userInput['text'], userInput['num_beams'])
    tokenized_input = tokenizer(input_string, return_tensors='pt').to(device)
    encoded_output = model.generate(**tokenized_input, max_length=1000)[0]
    decoded = tokenizer.decode(encoded_output, skip_special_tokens=True)
    return {
        'Paraphrase': decoded
        }
